Summary: You will compile and run one of the code examples we have seen in-class (from our GitHub repository), benchmark its performance on your local computer, and try out making some simple modifications and assessing their impact on performance.

Objective: The primary objective is to make sure you can access/download, compile and run the code examples that have been prepared for you. For most students, it will be very easy to do so; but some of you might require some guidance if you are using some specific compiler, or build system; this would be an opportunity to try things out, and reach out for help and guidance if necessary (primarily via Piazza). You will also get a little hands-on experience on benchmarking and evaluating performance, and making simple adaptations to code while testing their impact on execution speed.

Deliverable: Place your code in a .zip archive, including a written report (e.g. in PDF, Word, or TXT format) and any auxiliary files for the sake of compilation (Makefiles, etc) and submit it through Canvas. In the written report (1-3 pages should suffice) make sure to include information on (a) What computer, including CPU model, you ran this on, (b) What operating system and compiler you used, and (c) How you compiled the code (e.g. did you compile and run via the command line? did you give any specific options? did you need to install anything particular for this to work?). The report should also include the findings of your performance evaluations, as described below. Optionally: you are welcome to state in your report how long it took you to complete this work; this will not impact your grade in any way, it will just help us calibrate the difficulty of these assignments. 

Effort: The median time commitment for this assignment will likely be around 4hrs. Some students will do this way faster; if you have already tried and successfully ran some of the examples, it might take you less than 20min of effort to just implement and run the prescribed modifications (and maybe 30min to write the report itself). Others might require a little bit more effort, if they encounter problems with compilation (you are encouraged to seek help/guidance early, on Piazza!) or questions related to "why does this run fast enough on my computer?". Again, this is not intended to be particularly difficult, just an opportunity to be exposed to the coding exercises we will be engaging in, and getting set-up with testing in a way that makes sense. Of course, if you need to catch up on the recorded lectures, before starting on the assignment, this would also take a little extra time!

Grading: Will be on a 5-point scale (roughly corresponding to 0%, 20%, 40%, 60%, 80% and 100% success). 

Deadline: Friday February 17th, at midnight.

Late policy: Canvas submission will remain open for 2 more days, till Sunday February 19th at midnight. Late submissions will be penalized with 1 point subtracted, in the 5-point grade scale. The first late assignment for each student in a semester will be "forgiven"; subsequent late submissions will carry the 1-point penalty. 

Description: Your assignment will be based on the 3D Laplacian example (as discussed in the Tuesday February 9th lecture), which can be found in the subdirectory LaplacianStencil/LaplacianStencil_0_10 of our GitHub repository (clone link : https://github.com/sifakis/CS639S23_Demos.gitLinks to an external site.; check out our online lectures for more details). Based on this code, you should do the following:

Make sure that you can successfully compile & run this code. Make sure that you "enable" OpenMP in whatever compiler you choose to use! If you encounter issues, please reach out (Piazza or Office Hours) for assistance. If everything works ok, please document in your report what compiler, operating system, and compilation commands (if compiling from the command line) you used. Make sure that you can control how many threads/cores you are using via OpenMP in the execution of this code (i.e. by setting the OMP_NUM_THREADS environmental variable; check that using 1-thread/core vs. all available cores/threads has an effect on runtime!)
Provide an estimate of the "effective bandwidth" that you are getting out of the execution of this benchmark. First, compute how much memory is read/written by every execution of this algorithm (we did this exact exercise with the 2D version of the Laplacian). For this you can compute how much memory is allocated into the two arrays u[] and Lu[], and divide that by the runtime reported by the execution of the algorithm to get an "effective bandwidth" (report this in GB/s in your writeup). Check if this performance figure is reasonable and expected: remember that on a typical workstation system that we used as an example in-class, we achieved about 60% of the "peak" memory bandwidth that the CPU was capable of (for Intel processors you can look up this info on https://ark.intel.com/Links to an external site. - check the lecture notes for more pointers on this). Are you getting something roughly similar? If not, for example if you are getting less than 10-20% of the "peak" bandwidth, check for culprits such as (a) the compiler has not turned on optimization - some compilers (e.g. Intel Compiler) tend to do that by default, others require an explicit command line option, (b) Did you use OpenMP?, (c) Do you have programs running in the background, or are there other users running different applications, if using a lab computer ... As before, if you are getting an unanticipated behavior, reach out to the instructional staff for hints/tips.
File Laplacian.cpp includes the following triple-for-loop
    for (int i = 1; i < XDIM-1; i++)
        for (int j = 1; j < YDIM-1; j++)
            for (int k = 1; k < ZDIM-1; k++)
            In the 2D version of the Laplacian stencil, we saw that swapping the order of these for loops can have a significant impact on performance. Try this out in this 3D example! You are welcome to try all 6 permutations if you like, but at least try the following two:
            (a) Iterating first in the Z direction, then Y direction, then X direction (the inverse of what is coded up), and
            (b) Keeping the first loop (X direction) the same, and swapping just the last two (i.e. iterating X direction first, then Z, then Y)
            Report the run times you got by making these changes (running on all available cores in your computer), and compare against the baseline implementation (as given to you in the code from GitHub). Add some brief commentary on these timings in your report. Does it make sense if things got much slower (if they did ... or faster if they did, too!). Does it make sense that a given change had a certain impact, but maybe not as severe of an impact that a different one had?
